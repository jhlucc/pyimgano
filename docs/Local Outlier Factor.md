LOF (Local Outlier Factor) 详解

LOF的核心思想是："一个点是否异常，要看它和它邻居的密度差异"

1. 直观理解
想象这样的场景：
城市中心（密集）          郊区（稀疏）
    
● ● ● ● ●                 ·   ·
● ● ● ● ●                ·     ·
● ● ○ ● ●               ·   ○   ·
● ● ● ● ●                ·     ·
● ● ● ● ●                 ·   ·

城市中的○：异常          郊区的○：正常
（周围都很密集，          （周围都很稀疏，
 它却远离其他点）          大家都这样）


2. LOF的关键概念
2.1 k-距离 (k-distance)
一个点到第k个最近邻居的距离

# 示例
点A的5个最近邻居距离：[0.1, 0.2, 0.3, 0.5, 0.8]
k-距离(k=5) = 0.8


LOF(A) = (邻居们的平均LRD) / (A的LRD)

LOF ≈ 1：正常（和邻居密度相似）
LOF > 1：异常（比邻居稀疏）
LOF < 1：比邻居更密集（也是正常）


6. LOF的局限性

计算复杂度高：O(n²)，大数据集会很慢

样本量中等 (<100 k) + 低维 (<30)：
先用 LOF（局部密度） 
k值敏感：k太小容易过拟合，k太大会忽略局部模式
边界效应：数据边界的正常点可能被误判

 在图像场景，往往先用 CNN / ViT 提取特征（如层激活平均池化），再在特征空间跑上面这些算法。这样既保持轻量推理，又能利用深特征的判别力。
LOF的精髓在于它的"局部"思想：不同区域有不同的正常标准。这对于你的程序界面检测特别有用，因为不同功能模块的界面可能本来就有不同的视觉特征。